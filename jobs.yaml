config:
   user: marawan.gamal # your username to check slurm status
   max_jobs: 10 # maximum number of jobs to run in parallel
   max_gpus: 10 # maximum number of GPUs to use in parallel

common_preamble_declarations:
  - "#!/bin/bash"
  - "#SBATCH --output=/home/mila/m/marawan.gamal/projects/rosa/outputs/slurm-%j.out"
  - "#SBATCH --error=/home/mila/m/marawan.gamal/projects/rosa/outputs/slurm-error-%j.out"
  - "#SBATCH --mem=10G                                         # Ask for 10 GB of RAM"
  - "#SBATCH --time=8:00:00                                    # The job will run for 8 hours"
  - "#SBATCH -x cn-g[005-012,017-026]"

common_preamble_runs:
  # 1. Load the required modules
  - module load python/3.8

  # 2. Load your environment
  - source /home/mila/m/marawan.gamal/.venv/rosa/bin/activate

  # 3. Copy your dataset on the compute node
  - cp -r /home/mila/m/marawan.gamal/.cache/huggingface $SLURM_TMPDIR/huggingface

groups:
#  - name: MET | E2E_NLG | GPT2-S HP Tuning
#    preamble:
#      - "#SBATCH --gres=gpu:2"
#    paralleljobs:
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=none train.lr=5e-5
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-2
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-1
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-2
#      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-1

  - name: MET | E2E_NLG | GPT2-S LoRA vs ROSA (rank varies)
    preamble:
      - "#SBATCH --gres=gpu:2"
    paralleljobs:
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=none train.lr=5e-5
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=none train.lr=2e-3
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=ia3 train.lr=2e-3
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=1
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=2
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=3
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=4
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=5
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=10
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=15
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=20
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-3 fnmodel.params.rank=25
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=1
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=2
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=3
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=3
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=4
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=5
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=10
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=15
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=20
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-3 fnmodel.params.rank=25
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=1 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=2 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=3 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=3 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=4 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=5 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=10 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=15 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=20 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa train.lr=2e-4 fnmodel.params.rank=25 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=1 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=2 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=3 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=3 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=4 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=5 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=10 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=15 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=20 fnmodel.params.use_scale=True
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=lora train.lr=2e-4 fnmodel.params.rank=25 fnmodel.params.use_scale=True

  - name: MET | E2E_NLG | GPT2-S ROSA (varying factorization mode Bottom/Top/Random)
    preamble:
      - "#SBATCH --gres=gpu:2"
    paralleljobs:
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa fnmodel.params.factorize_mode=bottom train.lr=2e-3
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa fnmodel.params.factorize_mode=top train.lr=2e-3
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa fnmodel.params.factorize_mode=bottom train.lr=5e-5
      - python train.py dataset.cache=$SLURM_TMPDIR/huggingface fnmodel.name=rosa fnmodel.params.factorize_mode=top train.lr=5e-5